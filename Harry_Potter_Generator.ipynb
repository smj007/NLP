{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Harry Potter Generator.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZsdtuVHbp9I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import tensorflow as tf"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS5HzpJTbp9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_names= ['1SorcerersStone.txt', '2ChamberofSecrets.txt', '3ThePrisonerOfAzkaban.txt', '4TheGobletOfFire.txt', '5OrderofthePhoenix.txt', '6TheHalfBloodPrince.txt', '7DeathlyHollows.txt']"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAojBtcjbsTW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "11654482-07cd-4379-82e2-3605a5289196"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljfy8n6cb2nb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/HarryPotter')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2ZbxGohbp9R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d8229d00-4938-4937-ff77-2bda84b3fb1c"
      },
      "source": [
        "with open('harry.txt', 'w') as out:\n",
        "    for file in file_names:\n",
        "        with open(file) as f:\n",
        "            out.write(f.read())\n",
        "    data = open('harry.txt').read()  \n",
        "    print ('Length of text: {} characters'.format(len(data)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Length of text: 6251651 characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rva8UFeNbp9V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "93c578a1-4f4f-40a3-b886-6cde4bac8b2e"
      },
      "source": [
        "print(data[:300])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Harry Potter and the Sorcerer's Stone \n",
            "\n",
            "CHAPTER ONE \n",
            "\n",
            "THE BOY WHO LIVED \n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They were the last people you'd expect to be involved in anything strange or mysterious, because they \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRTU2PW4bp9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#preprocess the data as needed\n",
        "\n",
        "vocab = sorted(set(data))\n",
        "ch2idx = {c:i for i, c in enumerate(vocab)}\n",
        "idx2ch = np.array(vocab)\n",
        "text_vector = np.array([ch2idx[c] for c in data])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EC9ChHsbp9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d107e37-7edd-4fd8-8908-4cc059f1d306"
      },
      "source": [
        "print(type(vocab))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zPureTymbp9f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "22b45bcc-6980-441b-8cac-666819232299"
      },
      "source": [
        "print(vocab[:40])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\t', '\\n', '\\x1f', ' ', '!', '\"', '$', '%', '&', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ2B7I2Ebp9k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "04ea0249-5dda-4bd9-fb97-5f04be0dd5f2"
      },
      "source": [
        "print('{} -- char to int -- {}'.format(repr(data[:13]), text_vector[:13]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Harry Potter ' -- char to int -- [39 64 81 81 88  3 47 78 83 83 68 81  3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P-vqKFvXbp9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_length = 100\n",
        "eg_per_epoch = len(data)//(seq_length + 1)\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_vector) #this fn will create an integer stream\n",
        "\n",
        "#batch them\n",
        "sequences = char_dataset.batch(seq_length + 1, drop_remainder = True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2WjFhLFbp9q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1c54c57f-794e-4cfb-b8ce-7233762e4990"
      },
      "source": [
        "for i in char_dataset.take(10):\n",
        "    print(idx2ch[i.numpy()])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "H\n",
            "a\n",
            "r\n",
            "r\n",
            "y\n",
            " \n",
            "P\n",
            "o\n",
            "t\n",
            "t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbvTvEuqbp9t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "58756162-441a-423b-f06e-8938258e00f4"
      },
      "source": [
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2ch[item.numpy()])))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\"Harry Potter and the Sorcerer's Stone \\n\\nCHAPTER ONE \\n\\nTHE BOY WHO LIVED \\n\\nMr. and Mrs. Dursley, of nu\"\n",
            "'mber four, Privet Drive, were proud to say that they were perfectly normal, thank you very much. They'\n",
            "\" were the last people you'd expect to be involved in anything strange or mysterious, because they jus\"\n",
            "\"t didn't hold with such nonsense. \\n\\nMr. Dursley was the director of a firm called Grunnings, which ma\"\n",
            "'de drills. He was a big, beefy man with hardly any neck, although he did have a very large mustache. '\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_holpsJbp9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(data):\n",
        "    inp = data[:-1]\n",
        "    target = data[1:]\n",
        "    return inp, target"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dUo-bvgbp9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = sequences.map(split)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dQ23LFbbp91",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6c7bcaff-082d-4e23-e49f-b250be18d44d"
      },
      "source": [
        "print(type(dataset))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'tensorflow.python.data.ops.dataset_ops.MapDataset'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCeS7GGkbp94",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "630c9d5a-9905-45aa-b37b-4159c195d10a"
      },
      "source": [
        "print(list(dataset))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts_4HEE2bp98",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eda37ff5-4586-4860-94df-f252d3c535d5"
      },
      "source": [
        "#create a buffer within which we can shuffle the elements\n",
        "\n",
        "batch_size = 64\n",
        "buffer_size = 10000\n",
        "\n",
        "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder = True)\n",
        "dataset"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOcDGrYHbp9_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Model\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "emb_dims = 300\n",
        "rnn_1 = 512  #num of rnn units\n",
        "rnn_2 = 256\n",
        "rnn_units = [rnn_1, rnn_2]\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SOnEJ-Ibp-C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d39131dc-6a88-4d85-e133-50491348b1d0"
      },
      "source": [
        "print(len(vocab))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "106\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeVXaSwmbp-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_builder(vocab_size, emb_dims, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, emb_dims, \n",
        "                                 batch_input_shape = [batch_size, None]),\n",
        "        \n",
        "        tf.keras.layers.GRU(rnn_1, return_sequences = True,\n",
        "                            stateful = True,\n",
        "                           recurrent_initializer = 'glorot_uniform'\n",
        "                           ),\n",
        "        \n",
        "        tf.keras.layers.GRU(rnn_2, return_sequences = True,\n",
        "                            stateful = True,\n",
        "                           recurrent_initializer = 'glorot_uniform'\n",
        "                           ), \n",
        "        \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhr8qJlwbp-J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = model_builder(vocab_size = vocab_size,\n",
        "                     emb_dims = emb_dims,\n",
        "                     rnn_units = rnn_units,\n",
        "                     batch_size = batch_size)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZjbxMwabp-L",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV5Cmcg0bp-M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "8359ae12-2963-48f2-9f57-4d93bc172db5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (64, None, 300)           31800     \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (64, None, 512)           1250304   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (64, None, 256)           591360    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (64, None, 106)           27242     \n",
            "=================================================================\n",
            "Total params: 1,900,706\n",
            "Trainable params: 1,900,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tylr-cdbbp-O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_fn(labels, logits):\n",
        "    calc_loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                labels, logits,\n",
        "                from_logits = True)\n",
        "    return calc_loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avx-fV2Nbp-R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer = 'Adam', loss = loss_fn, metrics = ['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUrQUV_5bp-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#setup the relevant ckpts\n",
        "\n",
        "checkpoint_dir = './train_ckpts'\n",
        "ckpt_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "ckpt_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath = ckpt_prefix,\n",
        "    save_weights_only = True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ6ZtW1vbp-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9c2be664-82c1-4eda-e624-9442a9d1180c"
      },
      "source": [
        "epochs = 50\n",
        "history = model.fit(dataset, epochs = epochs, callbacks=[ckpt_callback])\n",
        "latest_check = tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "967/967 [==============================] - 37s 38ms/step - loss: 1.7559 - accuracy: 0.4989\n",
            "Epoch 2/50\n",
            "967/967 [==============================] - 38s 40ms/step - loss: 1.2933 - accuracy: 0.6139\n",
            "Epoch 3/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.2234 - accuracy: 0.6319\n",
            "Epoch 4/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1891 - accuracy: 0.6409\n",
            "Epoch 5/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1667 - accuracy: 0.6469\n",
            "Epoch 6/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1505 - accuracy: 0.6513\n",
            "Epoch 7/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1378 - accuracy: 0.6548\n",
            "Epoch 8/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1275 - accuracy: 0.6578\n",
            "Epoch 9/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1195 - accuracy: 0.6597\n",
            "Epoch 10/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1123 - accuracy: 0.6618\n",
            "Epoch 11/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1065 - accuracy: 0.6635\n",
            "Epoch 12/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.1013 - accuracy: 0.6649\n",
            "Epoch 13/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0968 - accuracy: 0.6660\n",
            "Epoch 14/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0935 - accuracy: 0.6672\n",
            "Epoch 15/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0896 - accuracy: 0.6681\n",
            "Epoch 16/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0868 - accuracy: 0.6690\n",
            "Epoch 17/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0844 - accuracy: 0.6697\n",
            "Epoch 18/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0820 - accuracy: 0.6705\n",
            "Epoch 19/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0800 - accuracy: 0.6708\n",
            "Epoch 20/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0780 - accuracy: 0.6715\n",
            "Epoch 21/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0766 - accuracy: 0.6717\n",
            "Epoch 22/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0750 - accuracy: 0.6722\n",
            "Epoch 23/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0741 - accuracy: 0.6724\n",
            "Epoch 24/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0725 - accuracy: 0.6728\n",
            "Epoch 25/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0713 - accuracy: 0.6732\n",
            "Epoch 26/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0705 - accuracy: 0.6734\n",
            "Epoch 27/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0702 - accuracy: 0.6736\n",
            "Epoch 28/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0690 - accuracy: 0.6737\n",
            "Epoch 29/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0680 - accuracy: 0.6740\n",
            "Epoch 30/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0675 - accuracy: 0.6742\n",
            "Epoch 31/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0668 - accuracy: 0.6745\n",
            "Epoch 32/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0665 - accuracy: 0.6745\n",
            "Epoch 33/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0659 - accuracy: 0.6747\n",
            "Epoch 34/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0655 - accuracy: 0.6745\n",
            "Epoch 35/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0652 - accuracy: 0.6750\n",
            "Epoch 36/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0651 - accuracy: 0.6748\n",
            "Epoch 37/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0648 - accuracy: 0.6749\n",
            "Epoch 38/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0645 - accuracy: 0.6751\n",
            "Epoch 39/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0639 - accuracy: 0.6750\n",
            "Epoch 40/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0640 - accuracy: 0.6751\n",
            "Epoch 41/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0638 - accuracy: 0.6752\n",
            "Epoch 42/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0636 - accuracy: 0.6751\n",
            "Epoch 43/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0632 - accuracy: 0.6753\n",
            "Epoch 44/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0635 - accuracy: 0.6752\n",
            "Epoch 45/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0629 - accuracy: 0.6753\n",
            "Epoch 46/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0638 - accuracy: 0.6750\n",
            "Epoch 47/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0634 - accuracy: 0.6751\n",
            "Epoch 48/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0632 - accuracy: 0.6752\n",
            "Epoch 49/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0634 - accuracy: 0.6750\n",
            "Epoch 50/50\n",
            "967/967 [==============================] - 39s 40ms/step - loss: 1.0633 - accuracy: 0.6751\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Rekomfbp-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "da3ba9de-3072-4bc0-81a9-577065eee39a"
      },
      "source": [
        "model = model_builder(vocab_size, emb_dims, rnn_units, batch_size=1)\n",
        "model.load_weights(latest_check)\n",
        "model.build(tf.TensorShape([1, None]))\n",
        "model.summary()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (1, None, 300)            31800     \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (1, None, 512)            1250304   \n",
            "_________________________________________________________________\n",
            "gru_3 (GRU)                  (1, None, 256)            591360    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (1, None, 106)            27242     \n",
            "=================================================================\n",
            "Total params: 1,900,706\n",
            "Trainable params: 1,900,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK78nVnQbp-e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_text(model, start_string):\n",
        "\n",
        "  # Number of characters to generate\n",
        "  num_chars_generated = 1000\n",
        "\n",
        "  # Vectorize the ip string\n",
        "  input_eval = [ch2idx[s] for s in start_string]\n",
        "  input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "  # Empty string to store our results\n",
        "  text_generated = []\n",
        "\n",
        "  # Low results in more predictable text.\n",
        "  # Higher results in more surprising text.\n",
        "  # Experiment to find the best setting.\n",
        "  scaling = 0.5 \n",
        "\n",
        "  # batch size == 1\n",
        "  \n",
        "  model.reset_states()\n",
        "  for i in range(num_chars_generated):\n",
        "      predictions = model(input_eval)\n",
        "      # remove the batch dimension\n",
        "      predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "      # using a categorical distribution to predict the character returned by the model\n",
        "      predictions = predictions / scaling\n",
        "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "\n",
        "      # We pass the predicted character as the next input to the model\n",
        "      # along with the previous hidden state\n",
        "      input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "      text_generated.append(idx2ch[predicted_id])\n",
        "\n",
        "  return (start_string + ''.join(text_generated))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7F3h96Z2bp-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "33dbbd26-f3d5-43e1-f0bf-32f00ab38c60"
      },
      "source": [
        "print(generate_text(model, start_string=u\"Gryffindor \"))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gryffindor stopped to feel to think of himself. Indeed, he was still spinning along the corridor with his face. \"My Lord,\" said Harry. \"I don't know what the Dark Lord was the same way.\"\n",
            "\"What?\" said Ron, who was staring at him and pushed him away from the table, the walls were gliding toward her. She looked up at the sink of silver that he had no idea where the dementors going to have to be replaced by the fact that the fire had managed to see them as a friendly he was going to get through the window. Hagrid was a bit carried to save Ron’s greatest prisoners. Now there was no sign of anybody who had gone on and remember, he had not felt a good spell that he had been talking about why Snape could not have done it so much as he saw Hermione in the long mirror of the fire and felt the sign from the cabin. \"The Deluminator has ever seen.\"\n",
            "\"So my office is not a splitting elf, then returned to the mountains of some proceedings of foreound his own and pointing. There was no sign of the shadowy bank wi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqOFBUEQmuk9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a0ec725c-dc9a-4152-d418-0d3f940260ed"
      },
      "source": [
        "print(generate_text(model, start_string=u\"Hermione \"))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hermione called around the edge of the seventh floor, and he disappeared into the shadows and saw that he was sure that he was a good mouse. He seemed to be the one who knew what was inside it when he had never seen anyone else in the world was no more than to stop him bestowards the walls. The sword of Gryffindor table and a wide board on the other side of the walls, a fraction towards the door, her eyes wide open. He saw himself and had stood waiting for the friendship on the floor. He seemed to be standing to bring him to the common room, she turned his wand again, and he was still a master of the summer and the first time in more proofsons, but he was still she was in the first place. He was the only one thing to tell from the orphanage and shorter than the Death Eaters and the crowd of the prophecy outside his chest. \"So... my Lord, the marked the Wizarding world --\"\n",
            "\"I have no idea,\" said Harry. \"I suppose we can find out what it only encouragement?\" he asked Harry. \"Well, it was the same\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58GC8C5rmyLo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}